{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13919624,"sourceType":"datasetVersion","datasetId":8869702},{"sourceId":13924832,"sourceType":"datasetVersion","datasetId":8873465}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **Project_By:** Urmila kharwa\n\n# üöÄ Enterprise Hiring Co-Pilot\n\n**Multi-Agent HR Automation & Candidate Screening System ü§ñüß†**\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"üìñ **Project Overview**\n\nEnterprise **Hiring Co-Pilot** is an autonomous, multi-agent HR automation system designed to transform traditional hiring workflows into a proactive, intelligent, and fully automated recruitment pipeline.\n\nPowered by **Google‚Äôs Agent Development Kit (ADK) and Gemini models**, this Co-Pilot acts as a virtual HR coordinator ‚Äî continuously monitoring hiring tasks, parsing resumes, matching candidates, generating insights, and managing recruiter‚Äìagent communication with minimal human oversight.\n\nThe system replaces manual screening and follow-ups with a smart, context-aware HR assistant that handles:\n\nüìù **Automated resume parsing**  \nüéØ **JD-to-candidate matching**  \nüîç **Skill gap analysis**  \nüß† **AI-driven shortlisting**  \nüóÇÔ∏è **Candidate ranking and scoring**  \nüìä **Reporting & workflow coordination**\n","metadata":{}},{"cell_type":"markdown","source":"\nüéØ **Problem Statement**\n\nTraditional hiring workflows are slow, manual, and prone to human bias.  \nRecruiters spend excessive time parsing resumes, matching skills, and shortlisting candidates ‚Äî often leading to delays, inconsistent evaluations, and missed talent opportunities.\n\nEnterprises need an intelligent system that can automate end-to-end screening, analyze candidate‚ÄìJD fit accurately, and support HR teams with real-time insights for faster, data-driven hiring decisions.\n\nThe problem:  \n‚úîÔ∏è Too much manual resume screening  \n‚úîÔ∏è Inconsistent candidate evaluation  \n‚úîÔ∏è Slow JD‚Äìskill matching  \n‚úîÔ∏è High recruiter workload  \n‚úîÔ∏è Lack of automated insights & reporting  \n\nThis creates bottlenecks that reduce hiring speed, accuracy, and scalability.\n","metadata":{}},{"cell_type":"markdown","source":"üí° **The Solution**\n\nThe Enterprise Hiring Co-Pilot provides a fully automated, multi-agent HR system that eliminates manual screening, speeds up hiring, and delivers consistent, data-driven candidate evaluation.\n\n‚ú® **How the Solution Works (Key Highlights)**  \n‚Ä¢ ü§ñ Multi-agent pipeline that automates resume parsing, JD matching, ranking, and scoring  \n‚Ä¢ üß† AI-driven insights to improve decision-making and reduce human bias  \n‚Ä¢ ‚ö° Real-time coordination between agents for faster end-to-end hiring  \n‚Ä¢ üìä Auto-generated reports for recruiters and managers  \n‚Ä¢ üîÅ Continuous monitoring of candidates, tasks, and workflow  \n‚Ä¢ üèÜ Delivers faster, scalable, and more accurate hiring outcomes  \n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## **Project Overview**\nThe **Enterprise Hiring Co-Pilot** is an autonomous multi-agent system designed to streamline the recruitment process. It leverages AI agents to automate candidate screening, ranking, interview scheduling, and weekly HR reporting, enabling recruiters to focus on high-value decisions rather than manual tracking.\n\n**Key Features:**\n- Automated resume parsing and candidate analysis\n- Parallel ranking & feedback evaluation\n- Interview scheduling & reminders\n- Weekly consolidated hiring reports\n- Nudge/reschedule system for overdue tasks\n\n---\n\n## **Track Selected**\n**Enterprise Agents** ‚Äî Using specialized agents to manage recruitment workflows and decision-making autonomously.\n\n---\n\n## **Agent Architecture**","metadata":{}},{"cell_type":"markdown","source":"\n## üîÅ End-to-End Flow Diagram \n\n```\nUser / Recruiter üë§\n        ‚îÇ\n        ‚ñº\nHR Coordinator Agent ü§ñ\n        ‚îÇ\n        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Resume Parser Agent üìÑ\n        ‚îÇ\n        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ Candidate Pipeline (Parallel Agents) ‚ö°\n        ‚îÇ                  ‚îú‚îÄ‚îÄ Ranker Agent\n        ‚îÇ                  ‚îî‚îÄ‚îÄ Feedback Analysis Agent\n        ‚îÇ\n        ‚ñº\nCandidate Judge Agent ‚öñÔ∏è ‚Üí HITL Review ‚úÖ\n        ‚îÇ\n        ‚ñº\nWeekly HR Report üìä ‚Üí Distribution Agent üì©\n        ‚îÇ\n        ‚ñº\nNotifications & Automation üîî ‚è∞\n```\n\n---\n\n","metadata":{}},{"cell_type":"markdown","source":"# üìå End-to-End Hiring Pipeline \n\n---\n\n## **1Ô∏è‚É£ Recruiter / User Input**\n\n**Box Color:** Light Orange / Light Green\n\n**Content:**\n\n* Upload PDFs (resumes)\n* Provide Job Description (JD)\n\n‚û°Ô∏è *Arrow down to Orchestrator*\n\nüí° *Starting point where recruiters provide data & requirements.*\n\n---\n\n## **2Ô∏è‚É£ Orchestrator (HR Coordinator)**\n\n**Box Color:** Bold Blue\n\n**Content:**\n\n* Central pipeline management\n\n‚û°Ô∏è *Arrow down to Parser Agent*\n\nüí° *Root agent that coordinates all workflow steps.*\n\n---\n\n## **3Ô∏è‚É£ Parser Agent**\n\n**Box Color:** Light Blue / Cyan\n\n**Content:**\n\n* Extract structured JSON (skills, experience)\n* OCR fallback for scanned resumes\n\nüí° *Extracts & preprocesses candidate data.*\n\n---\n\n## **4Ô∏è‚É£ Ranker Agent**\n\n**Box Color:** Lavender / Light Purple\n\n**Content:**\n\n* Score resumes against JD\n* Sort candidates by job-fit\n\nüí° *Automated candidate ranking.*\n\n---\n\n## **5Ô∏è‚É£ Explainer Agent**\n\n**Box Color:** Light Green / Mint\n\n**Content:**\n\n* Summarize candidate strengths\n* Explain ranking decisions\n\nüí° *Generates human-readable insights.*\n\n---\n\n## **6Ô∏è‚É£ JSON Normalization**\n\n**Box Color:** Light Gray\n\n**Content:**\n\n* Remove extra markers/noise\n* Standardize keys\n\nüí° *Ensures clean & consistent structured data.*\n\n---\n\n## **7Ô∏è‚É£ Human-in-the-Loop (HITL)**\n\n**Box Color:** Orange / Red Highlight\n\n**Content:**\n\n* Recruiter reviews ranking\n* Adjust candidate order if needed\n\nüí° *Critical step ensuring fairness, transparency & human oversight.*\n\n---\n\n## **8Ô∏è‚É£ Metrics & Dashboard**\n\n**Box Color:** Teal / Blue\n\n**Content:**\n\n* Precision@K\n* NDCG\n* HITL-adjusted scoring\n\nüí° *Tracks the system‚Äôs performance & recruiter impact.*\n\n---\n\n## **9Ô∏è‚É£ Weekly Hiring Report & Distribution**\n\n**Box Color:** Green / Orange Highlight\n\n**Content:**\n\n* Generates weekly hiring summary\n* Sends email/notification to HR stakeholders\n\nüí° *Final system output: clean insights for managers.*\n\n---\n\n### ‚úÖ **Conclusion**\n\nThis pipeline provides an end-to-end multi-agent hiring workflow with:\n\n* Automated resume parsing\n* Intelligent ranking\n* Human oversight\n* Weekly reporting\n\n\n\n---\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## üìã Cleaned Table \n\n| Step                                        | Content                                                                              | Notes / Tooltip                                                   |\n| ------------------------------------------- | ------------------------------------------------------------------------------------ | ----------------------------------------------------------------- |\n| **1Ô∏è‚É£ Recruiter / User Input**              | ‚Ä¢ Upload PDFs (resumes)<br>‚Ä¢ Provide Job Description (JD)                            | üí° Starting point: recruiters provide data & requirements         |\n| **2Ô∏è‚É£ Orchestrator (HR Coordinator)**       | ‚Ä¢ Central pipeline management                                                        | üí° Acts as multi-agent system root; coordinates agents & workflow |\n| **3Ô∏è‚É£ Parser Agent**                        | ‚Ä¢ Extract structured JSON (skills, experience)<br>‚Ä¢ OCR fallback for scanned resumes | üí° Handles data extraction & preprocessing                        |\n| **4Ô∏è‚É£ Ranker Agent**                        | ‚Ä¢ Score resumes against Job Description<br>‚Ä¢ Sort candidates by fit                  | üí° Automated ranking based on candidate-job suitability           |\n| **5Ô∏è‚É£ Explainer Agent**                     | ‚Ä¢ Summarize candidate strengths<br>‚Ä¢ Generate explanations for ranking               | üí° Human-readable summaries of candidate scores                   |\n| **6Ô∏è‚É£ JSON Normalization**                  | ‚Ä¢ Remove extra text / markers<br>‚Ä¢ Standardize keys                                  | üí° Clean data for consistent storage & analysis                   |\n| **7Ô∏è‚É£ Human-in-the-Loop (HITL)**            | ‚Ä¢ Recruiter reviews ranking<br>‚Ä¢ Adjust order if needed                              | üí° Ensures fairness & validation before final decision            |\n| **8Ô∏è‚É£ Metrics & Dashboard**                 | ‚Ä¢ Precision@K<br>‚Ä¢ NDCG<br>‚Ä¢ HITL-adjusted scoring                                   | üí° Tracks system performance & recruiter interventions            |\n| **9Ô∏è‚É£ Weekly Hiring Report & Distribution** | ‚Ä¢ Generate weekly reports<br>‚Ä¢ Emails / Notifications to stakeholders                | üí° Final HR output: aggregated insights & actions                 |\n\n---\n\n \n","metadata":{}},{"cell_type":"markdown","source":"## üöÄ Project START ‚Äî Coding (placeholder)\n\nI've added a **Project START ‚Äî Coding** . ready code cells (imports, parser, ranker, explainer, HITL hooks, metrics, report) into the documentthe complete, runnable cells. ","metadata":{}},{"cell_type":"markdown","source":"üîë Key Components\n- Recruiter / User\n- Uploads candidate resumes (PDFs).\n- Provides the job description as the baseline for evaluation.\n- Orchestrator (HR Coordinator)\n- Acts as the central manager, ensuring smooth flow between agents.\n- Handles pipeline coordination and error recovery.\n- Parser Agent\n- Extracts structured data (JSON) from resumes.\n- Identifies skills, experience, and fallback OCR for scanned documents.\n- Ranker Agent\n- Scores resumes against the job description.\n- Produces a sorted candidate list based on fit.\n- Explainer Agent\n- Summarizes candidate strengths.\n- Generates human-readable explanations for why candidates are ranked as they are.\n- JSON Normalization\n- Cleans and standardizes extracted data.\n- Ensures consistent keys and removes noise.\n- Human-in-the-Loop (HITL)\n- Recruiter reviews rankings.\n- Adjusts order if needed, adding human judgment to AI scoring.\n- Metrics & Dashboard\n- Tracks performance with metrics like Precision@K and NDCG.\n- Incorporates HITL adjustments into scoring feedback loops.\n- Weekly Hiring Report & Distribution\n- Generates reports for stakeholders.\n- Sends via email/notifications.\n\n‚öôÔ∏è Strengths of This Design\n- Transparency: Explainer Agent ensures recruiters understand why candidates are ranked.\n- Flexibility: HITL allows human override, preventing blind reliance on AI.\n- Accountability: Metrics & dashboard provide measurable performance indicators.\n- Automation + Human Review: Balances efficiency with recruiter expertise.\n\n\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"‚öôÔ∏è Technical Implementation Details¬∂\nThis project is implemented using Python 3.11 and the Google Agent Development Kit (ADK).\n\n\nüìö Key Libraries & Models¬∂\nModel: gemini-2.5-flash for high-speed reasoning and gemini-2.5-flash-lite for simple routing tasks.\nFramework: google.adk (Agents, Runners, Tools).\n\nValidation: Pydantic schemas ensure structured data exchange between agents.","metadata":{}},{"cell_type":"markdown","source":"‚öôÔ∏è **Technical Implementation Details**\n\nThe Enterprise Hiring Co-Pilot is built using a modular, multi-agent architecture designed for scalability, automation, and enterprise-grade hiring workflows.\n\nüîß **Core Technologies Used**\n‚Ä¢ Python 3.11  \n‚Ä¢ Google Agent Development Kit (ADK)  \n‚Ä¢ Gemini Models (for parsing, ranking, and reasoning)  \n‚Ä¢ FastAPI (for orchestrator endpoints)  \n‚Ä¢ LangChain-based tool routing (optional)  \n‚Ä¢ Pandas & PyPDF for resume handling  \n‚Ä¢ Vector similarity for JD‚Äìcandidate matching  \n\nü§ñ **Multi-Agent System Design**\n‚Ä¢ Orchestrator Agent coordinates all tasks  \n‚Ä¢ Parser Agent extracts structured candidate data  \n‚Ä¢ JD Analyzer Agent processes role requirements  \n‚Ä¢ Ranker Agent generates job-fit scores  \n‚Ä¢ Explainer Agent produces insights & summaries  \n‚Ä¢ Metrics Agent tracks performance (Precision@K, NDCG)  \n\nüóÇÔ∏è **Data Flow**\n1. Resume (PDF) ‚Üí Parser Agent ‚Üí Structured JSON  \n2. JD ‚Üí JD Analyzer Agent  \n3. Candidate JSON + JD JSON ‚Üí Ranker Agent  \n4. Ranking ‚Üí Explainer Agent  \n5. Metrics ‚Üí Dashboard Layer  \n\nüõ†Ô∏è **Key Implementation Features**\n‚Ä¢ OCR support for scanned resumes  \n‚Ä¢ JSON normalization for consistency  \n‚Ä¢ Human-in-the-loop (HITL) adjustments  \n‚Ä¢ Weekly automated hiring reports  \n\nThis technical stack ensures a reliable, explainable, and fully automated hiring pipeline suitable for enterprise environments.\n","metadata":{}},{"cell_type":"markdown","source":"üåä **Data Flow & Processing Pipeline**\n\nThe Enterprise Hiring Co-Pilot processes recruitment data through a structured multi-agent workflow to ensure automation, accuracy, and human oversight.\n\n1Ô∏è‚É£ **Resume & JD Input**  \n‚Ä¢ Recruiters upload resumes (PDF/DOCX)  \n‚Ä¢ Job Descriptions (JDs) are submitted  \n\n2Ô∏è‚É£ **Parsing & Preprocessing**  \n‚Ä¢ Parser Agent extracts structured JSON (skills, experience)  \n‚Ä¢ OCR fallback for scanned resumes  \n‚Ä¢ JSON Normalization ensures consistent data  \n\n3Ô∏è‚É£ **Job Matching & Ranking**  \n‚Ä¢ JD Analyzer Agent identifies required skills  \n‚Ä¢ Ranker Agent scores candidates based on fit  \n‚Ä¢ Explainer Agent generates human-readable insights  \n\n4Ô∏è‚É£ **Human-in-the-Loop (HITL)**  \n‚Ä¢ Recruiters review ranking results  \n‚Ä¢ Adjustments are applied if necessary  \n\n5Ô∏è‚É£ **Analytics & Metrics**  \n‚Ä¢ Metrics Agent calculates Precision@K, NDCG, and other KPIs  \n‚Ä¢ Tracks system performance and recruiter impact  \n\n6Ô∏è‚É£ **Reporting & Distribution**  \n‚Ä¢ Weekly hiring reports generated  \n‚Ä¢ Insights shared with HR stakeholders via email/notification  \n\nThis pipeline ensures **end-to-end automation**, **data consistency**, and **transparent decision-making** in enterprise hiring.\n","metadata":{}},{"cell_type":"markdown","source":"‚ö° **Performance & Optimization**\n\nThe Enterprise Hiring Co-Pilot ensures fast, accurate, and scalable hiring workflows through continuous performance monitoring and system optimization.\n\nüîπ **Key Performance Metrics**\n‚Ä¢ Candidate ranking accuracy  \n‚Ä¢ Precision@K and NDCG scores  \n‚Ä¢ Human-in-the-loop adjustment impact  \n‚Ä¢ Processing time per resume  \n\nüîπ **Optimization Strategies**\n‚Ä¢ Parallel processing of resumes across multiple agents  \n‚Ä¢ Vector similarity optimization for JD-candidate matching  \n‚Ä¢ Caching frequently used candidate/skill data  \n‚Ä¢ Continuous feedback loop from recruiter HITL interactions  \n\nüîπ **Scalability Considerations**\n‚Ä¢ Modular multi-agent architecture for horizontal scaling  \n‚Ä¢ Cloud-based deployment options for large enterprise datasets  \n‚Ä¢ Real-time pipeline monitoring and error handling  \n\nThese strategies collectively ensure **efficient, reliable, and scalable end-to-end hiring automation**.\n","metadata":{}},{"cell_type":"markdown","source":"üíº **Business Impact**\n\nThe Enterprise Hiring Co-Pilot delivers measurable value to organizations by streamlining recruitment processes and improving hiring quality.\n\nüîπ **Time Savings**  \n‚Ä¢ Automated resume parsing and candidate ranking reduces recruiter workload  \n‚Ä¢ Speeds up the end-to-end hiring cycle  \n\nüîπ **Improved Candidate Quality**  \n‚Ä¢ AI-driven JD-to-candidate matching ensures better role fit  \n‚Ä¢ Reduces human bias in screening and selection  \n\nüîπ **Data-Driven Insights**  \n‚Ä¢ Metrics & dashboard provide actionable analytics  \n‚Ä¢ Informed decision-making for HR teams  \n\nüîπ **Scalability & Efficiency**  \n‚Ä¢ Multi-agent architecture supports high-volume recruitment  \n‚Ä¢ Enables enterprise-wide automation without additional headcount  \n\nüîπ **Human Oversight & Transparency**  \n‚Ä¢ HITL ensures fairness and accountability  \n‚Ä¢ Recruiters can intervene when needed to maintain quality  \n\nOverall, this system enhances **efficiency, accuracy, and strategic decision-making** in enterprise hiring.\n","metadata":{}},{"cell_type":"markdown","source":"üîÆ **Future Enhancements**\n\nThe Enterprise Hiring Co-Pilot is designed to evolve with emerging AI and HR technologies. Future improvements focus on enhancing automation, intelligence, and user experience.\n\nüîπ **Advanced Candidate Insights**  \n‚Ä¢ Predictive analytics for candidate performance  \n‚Ä¢ Sentiment analysis from cover letters and interviews  \n\nüîπ **Integration with External HR Systems**  \n‚Ä¢ Seamless sync with ATS, HRIS, and payroll systems  \n‚Ä¢ Real-time updates across platforms  \n\nüîπ **Enhanced Multi-Modal Data Processing**  \n‚Ä¢ Incorporate video, audio, and social media profiles  \n‚Ä¢ Improved candidate profiling beyond resumes  \n\nüîπ **Continuous Learning & Feedback Loops**  \n‚Ä¢ Model retraining based on recruiter interactions  \n‚Ä¢ Adaptive ranking algorithms for evolving role requirements  \n\nüîπ **Scalable Cloud & Enterprise Deployment**  \n‚Ä¢ Containerized deployment for global teams  \n‚Ä¢ Multi-tenant support for large organizations  \n\nThese enhancements aim to make the system more **intelligent, scalable, and fully autonomous**, while keeping human oversight for strategic decision-making.\n","metadata":{}},{"cell_type":"markdown","source":"üèÅ **Conclusion**\n\nProjectPilot demonstrates the power of Agentic AI in transforming administrative workflows. By combining the reasoning capabilities of Gemini 2.5 with the structured tooling of the Google ADK, we have created a system that doesn't just manage data‚Äîit manages work.\n\nFrom proactive nudges to strategic reporting, this project highlights how AI agents can become autonomous partners in the workforce, driving efficiency","metadata":{}},{"cell_type":"markdown","source":"‚öôÔ∏è **Section 1: Setup**\n\nThis section handles the initial setup of the environment for the Enterprise Hiring Co-Pilot project.\n\n1Ô∏è‚É£ **Install Dependencies**  \n \n  - Google ADK and Gemini SDK  \n\n2Ô∏è‚É£ **Configure Gemini API Key**  \n‚Ä¢ Sets up authentication to use the Gemini API.  \n‚Ä¢ Ensures secure access for LLM-powered agents and workflows.  \n.\n","metadata":{}},{"cell_type":"code","source":"# ===============================\n# 1Ô∏è‚É£ Install ADK + Setup\n# ===============================\n!pip install --upgrade google-adk\n!pip install pdfplumber\n\n# ===============================\n# 2Ô∏è‚É£ Load Gemini API Key (Kaggle Secrets)\n# ===============================\nimport os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"üîê Gemini API key loaded successfully.\")\nexcept Exception as e:\n    print(\"‚ùå ERROR: Add GOOGLE_API_KEY in Kaggle Secrets.\", e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:49:52.673310Z","iopub.execute_input":"2025-11-30T07:49:52.674205Z","iopub.status.idle":"2025-11-30T07:50:02.585961Z","shell.execute_reply.started":"2025-11-30T07:49:52.674178Z","shell.execute_reply":"2025-11-30T07:50:02.584631Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: google-adk in /usr/local/lib/python3.11/dist-packages (1.19.0)\nRequirement already satisfied: PyYAML<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from google-adk) (6.0.3)\nRequirement already satisfied: aiosqlite>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.21.0)\nRequirement already satisfied: anyio<5.0.0,>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (4.11.0)\nRequirement already satisfied: authlib<2.0.0,>=1.5.1 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.6.5)\nRequirement already satisfied: click<9.0.0,>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from google-adk) (8.3.0)\nRequirement already satisfied: fastapi<0.119.0,>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.116.1)\nRequirement already satisfied: google-api-python-client<3.0.0,>=2.157.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.177.0)\nRequirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.125.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.125.0)\nRequirement already satisfied: google-cloud-bigquery-storage>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.34.0)\nRequirement already satisfied: google-cloud-bigquery>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (3.35.1)\nRequirement already satisfied: google-cloud-bigtable>=2.32.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.34.0)\nRequirement already satisfied: google-cloud-discoveryengine<0.14.0,>=0.13.12 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.13.12)\nRequirement already satisfied: google-cloud-secret-manager<3.0.0,>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.25.0)\nRequirement already satisfied: google-cloud-spanner<4.0.0,>=3.56.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (3.56.0)\nRequirement already satisfied: google-cloud-speech<3.0.0,>=2.30.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.34.0)\nRequirement already satisfied: google-cloud-storage<4.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (3.5.0)\nRequirement already satisfied: google-genai<2.0.0,>=1.45.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.48.0)\nRequirement already satisfied: graphviz<1.0.0,>=0.20.2 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.21)\nRequirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (4.25.0)\nRequirement already satisfied: mcp<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.20.0)\nRequirement already satisfied: opentelemetry-api<=1.37.0,>=1.37.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-exporter-gcp-logging<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0a0)\nRequirement already satisfied: opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0a0)\nRequirement already satisfied: opentelemetry-exporter-gcp-trace<2.0.0,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.36.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-resourcedetector-gcp<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0a0)\nRequirement already satisfied: opentelemetry-sdk<=1.37.0,>=1.37.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.37.0)\nRequirement already satisfied: pyarrow>=14.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (19.0.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.12.4)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.9.0.post0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.9.0.post0)\nRequirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.2.1)\nRequirement already satisfied: requests<3.0.0,>=2.32.4 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.32.5)\nRequirement already satisfied: sqlalchemy-spanner>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.17.1)\nRequirement already satisfied: sqlalchemy<3.0.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.0.41)\nRequirement already satisfied: starlette<1.0.0,>=0.46.2 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.47.2)\nRequirement already satisfied: tenacity<10.0.0,>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (9.1.2)\nRequirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.11/dist-packages (from google-adk) (4.15.0)\nRequirement already satisfied: tzlocal<6.0,>=5.3 in /usr/local/lib/python3.11/dist-packages (from google-adk) (5.3.1)\nRequirement already satisfied: uvicorn<1.0.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.35.0)\nRequirement already satisfied: watchdog<7.0.0,>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (6.0.0)\nRequirement already satisfied: websockets<16.0.0,>=15.0.1 in /usr/local/lib/python3.11/dist-packages (from google-adk) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.9.0->google-adk) (3.11)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.9.0->google-adk) (1.3.1)\nRequirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib<2.0.0,>=1.5.1->google-adk) (46.0.3)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.22.0)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (2.38.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.2.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (2.28.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.2.0)\nRequirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.26.1)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (5.29.5)\nRequirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (25.0)\nRequirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.14.2)\nRequirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2.1.2)\nRequirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.17.0)\nRequirement already satisfied: cloudpickle<4.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.1.2)\nRequirement already satisfied: google-cloud-trace<2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.17.0)\nRequirement already satisfied: google-cloud-logging<4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.12.1)\nRequirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery>=2.2.0->google-adk) (2.4.3)\nRequirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery>=2.2.0->google-adk) (2.7.2)\nRequirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery-storage>=2.0.0->google-adk) (1.74.0)\nRequirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (0.14.2)\nRequirement already satisfied: google-crc32c<2.0.0dev,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (1.7.1)\nRequirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.5.3)\nRequirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.15.4)\nRequirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.45.0->google-adk) (0.28.1)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.23.0->google-adk) (25.4.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.23.0->google-adk) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.23.0->google-adk) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.23.0->google-adk) (0.26.0)\nRequirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (0.4.3)\nRequirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (2.11.0)\nRequirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.8.0->google-adk) (2.10.1)\nRequirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (0.0.20)\nRequirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (3.0.3)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (8.7.0)\nRequirement already satisfied: google-cloud-monitoring~=2.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0->google-adk) (2.28.0)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.70.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<=1.37.0,>=1.37.0->google-adk) (0.58b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.4.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.9.0.post0->google-adk) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (2025.10.5)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3.0.0,>=2.0->google-adk) (3.2.3)\nRequirement already satisfied: alembic in /usr/local/lib/python3.11/dist-packages (from sqlalchemy-spanner>=1.14.0->google-adk) (1.17.1)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1.0.0,>=0.34.0->google-adk) (0.16.0)\nRequirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.71.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.9.1)\nRequirement already satisfied: google-cloud-appengine-logging<2.0.0,>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.7.0)\nRequirement already satisfied: google-cloud-audit-log<1.0.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.4.0)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (3.0.9)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.45.0->google-adk) (1.0.9)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (3.23.0)\nRequirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.0.0)\nRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.26.4)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic->sqlalchemy-spanner>=1.14.0->google-adk) (1.3.10)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=2.0.0->cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.23)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2.4.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.6.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic->sqlalchemy-spanner>=1.14.0->google-adk) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2024.2.0)\nRequirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.8)\nRequirement already satisfied: pdfminer.six==20251107 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20251107)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.3.0)\nRequirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (5.1.0)\nRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20251107->pdfplumber) (46.0.3)\nRequirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\nüîê Gemini API key loaded successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"1.3: Import ADK components: Imports the required components from the Agent Development Kit (ADK) and the Generative AI library. This helps in organizing the code and ensures access to the necessary building blocks for creating agents","metadata":{}},{"cell_type":"code","source":"!apt-get install -y poppler-utils tesseract-ocr\n!pip install pytesseract pdf2image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:50:03.599492Z","iopub.execute_input":"2025-11-30T07:50:03.599839Z","iopub.status.idle":"2025-11-30T07:50:20.755064Z","shell.execute_reply.started":"2025-11-30T07:50:03.599807Z","shell.execute_reply":"2025-11-30T07:50:20.753830Z"}},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\ntesseract-ocr is already the newest version (4.1.1-2.1build1).\nThe following additional packages will be installed:\n  libpoppler-dev libpoppler-private-dev libpoppler118\nThe following NEW packages will be installed:\n  poppler-utils\nThe following packages will be upgraded:\n  libpoppler-dev libpoppler-private-dev libpoppler118\n3 upgraded, 1 newly installed, 0 to remove and 162 not upgraded.\nNeed to get 1,469 kB of archives.\nAfter this operation, 697 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-private-dev amd64 22.02.0-2ubuntu0.12 [199 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-dev amd64 22.02.0-2ubuntu0.12 [5,186 B]\nGet:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler118 amd64 22.02.0-2ubuntu0.12 [1,079 kB]\nGet:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.12 [186 kB]\nFetched 1,469 kB in 0s (10.7 MB/s)      \n(Reading database ... 128639 files and directories currently installed.)\nPreparing to unpack .../libpoppler-private-dev_22.02.0-2ubuntu0.12_amd64.deb ...\nUnpacking libpoppler-private-dev:amd64 (22.02.0-2ubuntu0.12) over (22.02.0-2ubuntu0.8) ...\nPreparing to unpack .../libpoppler-dev_22.02.0-2ubuntu0.12_amd64.deb ...\nUnpacking libpoppler-dev:amd64 (22.02.0-2ubuntu0.12) over (22.02.0-2ubuntu0.8) ...\nPreparing to unpack .../libpoppler118_22.02.0-2ubuntu0.12_amd64.deb ...\nUnpacking libpoppler118:amd64 (22.02.0-2ubuntu0.12) over (22.02.0-2ubuntu0.8) ...\nSelecting previously unselected package poppler-utils.\nPreparing to unpack .../poppler-utils_22.02.0-2ubuntu0.12_amd64.deb ...\nUnpacking poppler-utils (22.02.0-2ubuntu0.12) ...\nSetting up libpoppler118:amd64 (22.02.0-2ubuntu0.12) ...\nSetting up poppler-utils (22.02.0-2ubuntu0.12) ...\nSetting up libpoppler-dev:amd64 (22.02.0-2ubuntu0.12) ...\nSetting up libpoppler-private-dev:amd64 (22.02.0-2ubuntu0.12) ...\nProcessing triggers for man-db (2.10.2-1) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.8) ...\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\nRequirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\nRequirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\nRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (25.0)\nRequirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.3.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\n\nprint(\"Folders in /kaggle/input:\")\nprint(os.listdir(\"/kaggle/input\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:50:20.756994Z","iopub.execute_input":"2025-11-30T07:50:20.757308Z","iopub.status.idle":"2025-11-30T07:50:20.764447Z","shell.execute_reply.started":"2025-11-30T07:50:20.757275Z","shell.execute_reply":"2025-11-30T07:50:20.763313Z"}},"outputs":[{"name":"stdout","text":"Folders in /kaggle/input:\n['cv-demo', 'architecture']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"1.4: Define Constants and Session Services: Initializes constants for the application and sets up in-memory session and memory services to manage the conversational state.","metadata":{}},{"cell_type":"code","source":"import os\nos.listdir(\"/kaggle/input/cv-demo\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:50:26.314078Z","iopub.execute_input":"2025-11-30T07:50:26.314434Z","iopub.status.idle":"2025-11-30T07:50:26.331691Z","shell.execute_reply.started":"2025-11-30T07:50:26.314405Z","shell.execute_reply":"2025-11-30T07:50:26.330825Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['Document 69.pdf',\n 'Document 69 (2).pdf',\n 'Document 69 (3).pdf',\n 'Document 69 (1).pdf',\n 'Document 69 (4).pdf']"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"resume_folder = \"/kaggle/input/cv-demo\"\n\nimport os\n\nprint(\"Files inside folder:\")\nprint(os.listdir(resume_folder))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:50:29.569196Z","iopub.execute_input":"2025-11-30T07:50:29.569529Z","iopub.status.idle":"2025-11-30T07:50:29.575929Z","shell.execute_reply.started":"2025-11-30T07:50:29.569505Z","shell.execute_reply":"2025-11-30T07:50:29.574929Z"}},"outputs":[{"name":"stdout","text":"Files inside folder:\n['Document 69.pdf', 'Document 69 (2).pdf', 'Document 69 (3).pdf', 'Document 69 (1).pdf', 'Document 69 (4).pdf']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ==========================================\n# Fixed: End-to-End Kaggle Notebook\n# ==========================================\nimport json, os, time, logging, re\nimport numpy as np\nimport pdfplumber\nfrom pdf2image import convert_from_path\nimport pytesseract\n\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s ‚Äî %(levelname)s ‚Äî %(message)s\")\nlogger = logging.getLogger(\"resume_screener\")\n\nREQUEST_COUNT = 0\nLATENCIES = []\n\nfrom google.adk.agents import Agent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import BaseTool\nfrom google.genai import types\n\n# ---------------------------\n# Retry config\n# ---------------------------\nretry_config = types.HttpRetryOptions(\n    attempts=5,\n    exp_base=6,\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:51:07.386909Z","iopub.execute_input":"2025-11-30T07:51:07.387573Z","iopub.status.idle":"2025-11-30T07:51:13.818539Z","shell.execute_reply.started":"2025-11-30T07:51:07.387545Z","shell.execute_reply":"2025-11-30T07:51:13.817429Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"\n# ---------------------------\n# PDF loader\n# ---------------------------\ndef pdf_to_text(pdf_path):\n    text = \"\"\n    try:\n        with pdfplumber.open(pdf_path) as pdf:\n            for p in pdf.pages:\n                t = p.extract_text()\n                if t: text += t\n    except Exception as e:\n        print(\"‚ùå pdfplumber error:\", e)\n\n    if not text.strip():\n        print(f\"üü° Using OCR for scanned PDF ‚Üí {os.path.basename(pdf_path)}\")\n        try:\n            images = convert_from_path(pdf_path)\n            for img in images:\n                text += pytesseract.image_to_string(img)\n        except Exception as e:\n            print(\"‚ùå OCR failed for:\", pdf_path, str(e))\n    return text.strip()\n\n# ---------------------------\n# Load resumes\n# ---------------------------\nresume_path = \"/kaggle/input/cv-demo/\"\nif not os.path.exists(resume_path):\n    raise FileNotFoundError(f\"Resume folder not found: {resume_path}\")\n\nresumes_text = []\npdf_files = [f for f in os.listdir(resume_path) if f.lower().endswith(\".pdf\")]\n\nfor file_name in pdf_files:\n    full_path = os.path.join(resume_path, file_name)\n    text = pdf_to_text(full_path)\n    if text:\n        resumes_text.append(text)\n        print(\"üìÑ Loaded:\", file_name)\n\nprint(f\"‚úÖ Total Resumes Loaded: {len(resumes_text)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:52:15.010083Z","iopub.execute_input":"2025-11-30T07:52:15.010722Z","iopub.status.idle":"2025-11-30T07:52:35.504778Z","shell.execute_reply.started":"2025-11-30T07:52:15.010667Z","shell.execute_reply":"2025-11-30T07:52:35.503528Z"}},"outputs":[{"name":"stdout","text":"üü° Using OCR for scanned PDF ‚Üí Document 69.pdf\nüìÑ Loaded: Document 69.pdf\nüü° Using OCR for scanned PDF ‚Üí Document 69 (2).pdf\nüìÑ Loaded: Document 69 (2).pdf\nüü° Using OCR for scanned PDF ‚Üí Document 69 (3).pdf\nüìÑ Loaded: Document 69 (3).pdf\nüü° Using OCR for scanned PDF ‚Üí Document 69 (1).pdf\nüìÑ Loaded: Document 69 (1).pdf\nüü° Using OCR for scanned PDF ‚Üí Document 69 (4).pdf\nüìÑ Loaded: Document 69 (4).pdf\n‚úÖ Total Resumes Loaded: 5\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\n# ==========================================\n# Define Agents\n# ==========================================\nparser_agent = Agent(\n    name=\"parser_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    instruction=\"\"\"\nConvert resume text into JSON:\n{\n \"name\": \"\",\n \"skills\": [],\n \"years_experience\": \"\",\n \"summary\": \"\"\n}\nReturn ONLY JSON.\n\"\"\"\n)\n\nranker_agent = Agent(\n    name=\"ranker_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    instruction=\"Rank candidates based on job description and return JSON list sorted by score descending.\"\n)\n\nexplainer_agent = Agent(\n    name=\"explainer_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    instruction=\"Summarize the ranking for the hiring manager.\"\n)\n\n# ==========================================\n# Tools\n# ==========================================\nclass ParserTool(BaseTool):\n    def call(self, task): return parser_agent.run(task).text\n\nclass RankerTool(BaseTool):\n    def call(self, task): return ranker_agent.run(task).text\n\nclass ExplainerTool(BaseTool):\n    def call(self, task): return explainer_agent.run(task).text\n\nparser_tool = ParserTool(name=\"parser_agent\", description=\"Parse resumes\")\nranker_tool = RankerTool(name=\"ranker_agent\", description=\"Rank resumes\")\nexplainer_tool = ExplainerTool(name=\"explainer_agent\", description=\"Explain ranking\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:53:04.104431Z","iopub.execute_input":"2025-11-30T07:53:04.105217Z","iopub.status.idle":"2025-11-30T07:53:04.113088Z","shell.execute_reply.started":"2025-11-30T07:53:04.105190Z","shell.execute_reply":"2025-11-30T07:53:04.112048Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\n\n\n\n# ==========================================\n# Orchestrator\n# ==========================================\norchestrator = Agent(\n    name=\"orchestrator_resume_screener\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    tools=[parser_tool, ranker_tool, explainer_tool],\n    instruction=\"\"\"\nPipeline: parser -> ranker -> explainer\nReturn JSON:\n{\n \"parsed_resumes\": [...],\n \"ranking\": [...],\n \"explanation\": \"\"\n}\nOnly JSON.\n\"\"\"\n)\n\nrunner = InMemoryRunner(agent=orchestrator)\nprint(\"üöÄ Multi-Agent Orchestrator Ready\")\n\n# ==========================================\n# Payload\n# ==========================================\njob_description = \"\"\"\nWe need an ML Engineer with Python, TensorFlow, NLP, 3+ years experience.\nBonus: Docker, Kubernetes.\n\"\"\"\n\npayload = {\"job_description\": job_description, \"resumes\": resumes_text}\nif not payload[\"resumes\"]:\n    raise ValueError(\"‚ùå No resumes found. Load them in /kaggle/input/cv-demo.\")\n\n# ==========================================\n# Fix asyncio for notebook\n# ==========================================\nimport nest_asyncio\nnest_asyncio.apply()\nimport asyncio\n\nasync def run_pipeline():\n    global REQUEST_COUNT\n    REQUEST_COUNT += 1\n    start = time.time()\n    response = await runner.run_debug(json.dumps(payload))\n    LATENCIES.append(time.time() - start)\n    logger.info(f\"Processed in {LATENCIES[-1]:.2f}s\")\n    return response\n\nresponse = asyncio.get_event_loop().run_until_complete(run_pipeline())\n\n# ==========================================\n# ===== Robust JSON Extraction + Normalization + HITL ======\n# ==========================================\nimport re\nimport json\n\ndef extract_all_json_blocks(text):\n    \"\"\"Finds all {...} or [...] blocks and returns them as Python objects\"\"\"\n    text = re.sub(r\"```json|```\", \"\", text, flags=re.IGNORECASE)\n    matches = re.findall(r\"(\\{.*?\\}|\\[.*?\\])\", text, flags=re.DOTALL)\n    objs = []\n    for m in matches:\n        try:\n            objs.append(json.loads(m))\n        except:\n            continue\n    return objs\n\n# Extract LLM output\nfinal_event = response[-1] if isinstance(response, (list, tuple)) else response\nllm_text = getattr(final_event, \"text\", str(final_event))\n\njson_blocks = extract_all_json_blocks(llm_text)\nif not json_blocks:\n    print(\"‚ùå No valid JSON blocks found\")\n    result = None\nelse:\n    # Merge parsed blocks (assuming one main dict with 'parsed_resumes', 'ranking', 'explanation')\n    main_obj = {}\n    for block in json_blocks:\n        if isinstance(block, dict):\n            main_obj.update(block)\n    result = main_obj\n    print(\"‚úÖ JSON parsed successfully with\", len(json_blocks), \"blocks\")\n\n# Normalize ranking keys\nif result and \"ranking\" in result:\n    for r in result[\"ranking\"]:\n        if \"schema:name\" in r:\n            r[\"name\"] = r.pop(\"schema:name\")\n\n# -----------------------------\n# Human-in-the-Loop (HITL) review\n# -----------------------------\nif result and \"ranking\" in result:\n    print(\"\\nüìã Human-in-the-Loop: Review and adjust rankings\")\n    for i, r in enumerate(result[\"ranking\"], start=1):\n        print(f\"{i}. {r.get('name','Unknown')} | Score: {r.get('score','N/A')}\")\n    \n    print(\"\\nEnter new order as comma-separated indices (or press Enter to keep as is):\")\n    try:\n        new_order = input()\n        if new_order.strip():\n            indices = [int(x.strip())-1 for x in new_order.split(\",\")]\n            result[\"ranking\"] = [result[\"ranking\"][i] for i in indices]\n            print(\"‚úÖ Rankings updated based on HITL input\")\n        else:\n            print(\"‚úÖ Rankings kept as is\")\n    except Exception as e:\n        print(\"‚ö†Ô∏è Invalid input, keeping original ranking. Error:\", e)\n\n# -----------------------------\n# Compute Metrics\n# -----------------------------\nif result and \"ranking\" in result:\n    ranked = result[\"ranking\"]\n    truth = {r.get(\"name\",\"\"): 1 if \"ML\" in r.get(\"name\",\"\") else 0 for r in ranked}\n\n    precision_at_k = lambda rank, truth, k: sum(truth.get(r.get(\"name\",\"\"),0) for r in rank[:k])/max(k,1)\n    ndcg = lambda rank, truth: (\n        sum(truth.get(r.get(\"name\",\"\"),0)/np.log2(i+2) for i,r in enumerate(rank)) /\n        sum(sorted(truth.values(), reverse=True)[i]/np.log2(i+2) for i in range(len(truth))) \n        if truth else 0\n    )\n\n    print(\"\\nüìä Metrics after HITL adjustment:\")\n    print(\"Precision@2 =\", precision_at_k(ranked, truth, 2))\n    print(\"NDCG =\", ndcg(ranked, truth))\nelse:\n    print(\"‚ö†Ô∏è Ranking array empty or JSON invalid.\")\n\n# -----------------------------\n# Final Conclusion\n# -----------------------------\nprint(\"\"\"\nüìå **Conclusion ‚Äî Multi-Agent Resume Screener**\n‚úî PDF resumes loaded\n‚úî Parser -> Ranker -> Explainer pipeline executed\n‚úî Robust JSON extraction applied\n‚úî Human-in-the-Loop review enabled\n‚úî Metrics computed after HITL\n\"\"\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:54:44.025670Z","iopub.execute_input":"2025-11-30T07:54:44.026670Z","iopub.status.idle":"2025-11-30T07:54:58.834569Z","shell.execute_reply.started":"2025-11-30T07:54:44.026638Z","shell.execute_reply":"2025-11-30T07:54:58.833701Z"}},"outputs":[{"name":"stdout","text":"üöÄ Multi-Agent Orchestrator Ready\n\n ### Created new session: debug_session_id\n\nUser > {\"job_description\": \"\\nWe need an ML Engineer with Python, TensorFlow, NLP, 3+ years experience.\\nBonus: Docker, Kubernetes.\\n\", \"resumes\": [\"Jeane Schme\\n\\nMachine Learning Engineer\\n\\n \\n\\nContact Details\\nte) Jeaneschme@gmail.com\\n@ (276) 984 5535\\n\\nO Goyetteborough, 78903,\\nArizona\\n\\nEducation\\n\\n@ Bachelor of Science in\\nComputer Science\\nUniversity of California,\\nBerkeley\\n2017 - 2021\\n\\nSkills\\n\\nData Science - Expert\\n\\nPython Programming - Expert\\nNeural Networks - Expert\\nAlgorithm Design - Expert\\nModel Building - Expert\\n\\nData Visualization - Expert\\n\\nSummary\\n\\nExperienced Machine Learning Engineer with 5+ years in the field and a\\npassion for developing cutting-edge Al solutions. Expert in Python and\\nTensorFlow, leveraging deep learning to create innovative models.\\n\\nWork Experience\\n\\nMachine Learning Engineer, O'Connell - Macejkovic\\nMarch 2023 - Present\\n* Developed machine learning solutions for a variety of industries,\\nincluding finance and healthcare, utilizing methods such as\\ndecision trees and logistic regression.\\n\\u00a2 Improved machine learning models\\u2019 accuracy by 20% through the\\noptimization of feature engineering, hyperparameter tuning, and\\nmodel selection techniques.\\n* Created custom algorithms with Python and Scikit-learn to\\nprocess and analyze large datasets.\\nMachine Learning Engineer, Wuckert Inc\\nMay 2021 - February 2023\\n* Developed user interfaces with TensorFlow and Keras for real-\\ntime model evaluation and insight generation.\\n* Collaborated with data scientists to develop a deep learning\\nmodel for image recognition.\\n* Utilized natural language processing (NLP) to extract meaningful\\ninsights from text data.\\n\\nReferences\\n\\nReferences available upon request\", \"RAHUL KHANNA\\n\\n2: 9953776253 | &: info@getsetresumes.com | _ Linkedin: linkedin.com/company/getsetresumes\\n\\n \\n\\nMACHINE LEARNING ENGINEER - leveraging +5 years of experience\\n\\nInnovative Machine Leaming Engineer with 5+ years of experience in application design, development, testing, and deployment.\\nHighly experienced in writing codes and algorithms as well as building complex neural networks through various programming\\nlanguages, Possess an unbridled passion for machine learning with comprehensive knowledge of machine learning concepts and\\nother related technologies. Unmatched abilities to identify, understand, and translate program requirements into sustainable,\\nadvanced technical solutions through C#, C+*. JavaScript, Python, and other programs for continuous improvement of Al\\ntechnologies.\\n\\n \\n\\nPROFILE SUMMARY\\n\\n* Experienced in python data manipulation for loading and extraction as well as with python libraries such as NumPy, SciPy and\\nPandas for data analysis and numerical computations.\\n\\n* Proficient in machine learning and deep learning skills for multiple applications including Computer Vision, Recommendation\\nSystems and Natural Language Processing\\n\\n\\u00ae Strong coding ability both in producing clean and efficient code as well as debugging and understanding large code bases\\n\\n* Extensive hands-on experience and high proficiency with structures, semi-structured and unstructured data, using a broad range\\nof data science programming languages and big data tools including R, Python, Spark, SQL, Scikit Learn, Hadoop Map Reduce\\n\\n* Highly skilled in using pandas, NumPy, Seabom, SciPy, matplotlib, sci-kit-learn, NLTK in Python for developing various machine\\n\\nleaming algorithms.\\n\\nCORE COMPETENCIES\\n\\n= Data and Quantitative Analysis = Machine Learning Algorithms = Predictive Modeling\\n* Predictive Modeling * Clustering Models * Data Structures\\n\\nPROFESSIONAL EXPERIENCE\\n\\nBellurbis LLC, Greater Noida Jan. 2019 - Oct. 2021\\n\\nMachine Learning Engineer\\n\\n* Developed and evaluated algorithms using machine leaming and statistical modelling techniques to increase performance, quality,\\ndata management, and accuracy.\\n\\n* Worked with Adobe's research teams to take cutting-edge research and tum it into excellent products and services.\\n\\n= Developed, simulated, tested, and improved algorithms for estimating electrical load and generation.\\n\\n* Consulted with managers to determine and refine machine learning objectives and developed ML algorithms to analyze huge\\nvolumes of historical data to make predictions.\\n\\n* Designed machine learning systems and self-running artificial intelligence (Al) software to automate predictive models.\\n\\n* Solved complex problems with multi-layered data sets, as well as optimized existing machine learning libraries and frameworks.\\n\\n* Designed lean proofs of concepts (POC) to answer targeted business questions. Explored and worked with a wide range of\\nproprietary, interesting data stores, Applied existing methods or developed new methods.\\n\\nClarivate, Greater Noida Sept. 2016 - Dec 2018\\n\\nMachine Learning Engineer\\n\\n* Developed and integrated large-scale, distributed machine learning system lifecycles utilising cutting-edge open source\\ntechnologies.\\n\\n= Created software that helps you increase your rate of experimentation and make better decisions on what to explore next.\\n\\n* Improved distributed cloud GPU training approaches for deep learning models, including data distribution editing, data quality\\nimprovements, and representation learning with self-supervision\\n\\n* Collaborated with multi-disciplinary product development teams to find possibilities for performance improvement and\\nincorporate trained models.\\n\\n* Developed a machine leaming pipeline and trained models with the end-to-end Bayesian segmentation setwork, resulting in a\\n$400000 annual savings.\\n\\n= Expertise in using PyTorch, TensorFlow, and Keras to train and deploy CNN, LSTM, and other Sequence models on Azure and AWS.\\n\\nACADEMIC CREDENTIALS\\n* Bachelor's Degree in Computer Science | Amity University , Lucknow | 2016\\n* Programming Languages: Python | R Programming | JavaScript/Java | Julia | Lisp\", \"+92 330-872-8087\\n\\nyouremail@gmailcom\\n\\nHari\\n\\nMACHINE LEARNING\\nENGINEER\\n\\nyouremail@gmail-com\\n\\nPlot 2-5/14, Jr Colony\\n\\n \\n\\nPROFILE\\n\\nLorern ipsum dolor sit amet, consectetur adipiscing elit, sed do\\n\\n \\n\\neiusmod tempor incididunt ut labore et dolore magna aliqua\\n\\n   \\n\\nLorem ipsurn dolor sit amet, consectetur adipiscing elit, sed do\\n\\n \\n\\n2iusmod tempor incididunt ut tabore et dolore magna aliqua\\n\\nFOLLOW ME WORK EXPERIENCE\\n\\n \\n\\n \\n\\n    \\n\\n; MACHINE LEARNING ENGINEER\\neer TIGER ANALYTICS\\neer Le Vem ipsum dolor sit amet, consectetur\\nLdipis g elit, sed do ewsmod tempc\\naha cy 5 ncididunt ut labore et d re magna\\nait sch Ligu\\nLinkedin, QUANTIPHI MACHINE LEARNING ENGINEER\\nve ipsury j t sita et, consectetur\\nWebsite adipiscing elit, sed do elusmod tempc\\nrer Wy cldidunt ut labore et dolore magna aliqua\\nTcs MACHINE LEARNING ENGINEER\\n19 Pat rem ipsurr ; or sit amet, consectetur\\nrdipiscing elit, sed do eiusmod tempc\\nwididuat ut ore re magna aliqua\\ntT MASTERS IN MACHINE LEARNING\\nLorem ipsum do sit amet, consectet\\nidipiscing elit, sed do elusmod tempor\\nANNA UNIVERSITY BACHELORS IN DATA SCIENCE\\nmi 4 Jol ta t ons t\\ntig r t, se elust te or\\n\\nREFERENCE\\n\\nLANGUAGES\\n\\nar i\\n\\nJORDAN STEVEN MATHEW SMITH\\n\\nENIOR MANAGER EN\\n\\n32 330-8728087 +9 30-87 2aC\", \"CONTACT\\n\\n& info@resumekraft\\n\\niLinois, U\\n\\nSKILLS\\n\\nOPERATING SYSTEM\\nShins ts eee RA ls) eniat ees)\\n\\nAPPLICATION SERVER\\nAVS EC Gooale ( e\\n\\nt. Bitbucket\\n\\nPROGRAMMING LANGUAGES\\n\\ney NEAT NS\\n\\nAvSO Ae\\n\\nFRAMEWORK\\n\\nDjango, Flask\\n\\nPROFESSIONAL TOOLS\\n\\nre ML Studio\\n\\n \\n\\nChrista Frank\\n\\nSENIOR MACHINE LEARNING ENGINEER\\n\\n \\n\\nSUMMARY\\n\\n* ML engineer seeks opportunities to solve real world problems.\\n\\n* Having a technical background and business analytical mind help to\\ncollaborate with team in order to reach defined goal\\n\\n* Experience in full life cycle development of chat bots in real time enterprise\\nenvironment\\n\\n* Experience in areas of Azure Machine Learning Studio, Keras, RASA,\\nNLP, Python, Django, Artificial Neural Network, Data Wrangling & Data\\nMining\\n\\nEXPERIENCE\\n\\nSystem Analyst\\nGraymatrix Solutions Pvt. Ltd.\\n\\nSep 2021 - Present\\n\\n\\u00ab Research on intent detection and named entity recognition approaches for\\nchatbots\\n\\n* Giving consultations and recommendations on chatbot development\\n(healthcare chathot, mental health chatbot, financial assistant)\\n\\n* Reviewing and improving existing conversation flows and chatbot\\nimplementations\\n\\n* Managing chatbot development processes\\n\\n\\u00ab User acceptance testing and training were conducted on-site at the\\ncustomer\\n\\n* Developed Al solutions like sale forecasting, sentiment analysis, language\\ndetection, etc. using Azure Machine Learning Studio.\\n\\nMachine Learning Engineer Mar 2020 - Aug 2021\\nPassive Referral\\n\\u00ab | was responsible for the technical implementation of the chatbot from\\nscratch\\ne Responsible for real time conversational bot development starting from\\ndevelopment phase getting requirement, bot development, testing, and bot\\ndeployment\\n\\u00a2 | was in charge of training the assistant, labelling the data, adding new\\nfeatures and iteratively improving it\\n* Worked on both with voice and text-based chatbots\\n* Worked on building machine learning models for context recognition using\\n\\nTensorflow libraries\\n\\nMachine Learning Intern Jun 2019 - Nov 2019\\n\\nHenry Harvin Education\\n\\ne Machine Learning Intern responsible to create machine learning models\", \"info@resumekraft.com\\nORs earn\\n9 Chicago, Illinois, US\\n\\nin linkedin com/resumekraft\\n\\nSKILLS\\neaster a3\\nAutomation studio\\nCAD\\n\\nETS KNX program\\n\\nMathlab\\n\\nLANGUAGES\\n\\nPERSONAL SKILLS\\n\\nCommunication\\n\\nMotivation to learn\\n\\nResult-oriented\\n\\nAnalytical mind\\n\\nEnthusiasm & optimism\\n\\nere alate]\\n\\natt alge)\\n\\n \\n\\nRyan Watson\\n\\nAUTOMATION AND MACHINE LEARNING\\nENGINEER\\n\\n \\n\\nSUMMARY\\n\\nFreshly Master Degree graduated student from the Northeastern University of\\nChina. A graduate student who had spent 4 years of learning and researching\\nComputer Vision in the matter of detecting and classified object using a digital\\ncamera in Autonomous Vehicle Laboratory.\\n\\nAbility to use (data) statistics and machine learning for finding complex data\\npatterns that drive meaningful impact on the business,\\n\\n| am looking for the opportunity to build a challenging career and apply my skills\\n\\nin an innovative and simple process. | enjoy working in a team and\\ncommunicating data-driven results.\\n\\nEXPERIENCE\\n\\nSystem Engineer Feb 2015 - Oct 2015\\nSmart home Life+\\n\\u00ab System Engineer, Production staff and Inner house wiring designer for Smart\\nhome with KNX standard:\\n* Establish operation strategy for construction with KNX standard.\\n* Prepare data and information for making regular report data analysis\\n\\nProduction Planning Feb 2016 - Sep 2016\\nLG Electronic Vietnam-Haiphong\\n\\n\\u00a2 Production Planning for LG Electronic Vietnam Haiphong;\\n\\n* Planning Production for Assembly Line inside the factory.\\n\\n* Prepare data and information for making regular report data analysis.\\n\\nEDUCATION\\n\\nMaster of Control Theory Sep 2016 - May 2020\\nSan Jose State University\\n\\nBachelor of Automation and Technology Aug 2010 - May 2015\\nNortheastern University\\n\\nPROJECT AND THESIS\\n\\nA study on pedestrian and vehicle detection based Jan 2020- Aug\\n\\non Convolutional Neural Network 2020\\nMaster Degree Final Project\"]}\n","output_type":"stream"},{"name":"stderr","text":"2025-11-30 07:54:44,306 ‚Äî INFO ‚Äî Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n2025-11-30 07:54:44,307 ‚Äî INFO ‚Äî AFC is enabled with max remote calls: 10.\n2025-11-30 07:54:58,824 ‚Äî INFO ‚Äî Response received from the model.\n2025-11-30 07:54:58,826 ‚Äî INFO ‚Äî Processed in 14.75s\n","output_type":"stream"},{"name":"stdout","text":"orchestrator_resume_screener > ```json\n{\n \"parsed_resumes\": [\n  {\n   \"name\": \"Jeane Schme\",\n   \"contact\": {\n    \"email\": \"Jeaneschme@gmail.com\",\n    \"phone\": \"(276) 984 5535\",\n    \"location\": \"Goyetteborough, 78903, Arizona\"\n   },\n   \"education\": \"Bachelor of Science in Computer Science, University of California, Berkeley, 2017 - 2021\",\n   \"skills\": [\n    \"Data Science - Expert\",\n    \"Python Programming - Expert\",\n    \"Neural Networks - Expert\",\n    \"Algorithm Design - Expert\",\n    \"Model Building - Expert\",\n    \"Data Visualization - Expert\"\n   ],\n   \"summary\": \"Experienced Machine Learning Engineer with 5+ years in the field and a passion for developing cutting-edge Al solutions. Expert in Python and TensorFlow, leveraging deep learning to create innovative models.\",\n   \"experience\": [\n    {\n     \"title\": \"Machine Learning Engineer\",\n     \"company\": \"O'Connell - Macejkovic\",\n     \"years\": \"March 2023 - Present\",\n     \"description\": \"Developed machine learning solutions for a variety of industries, including finance and healthcare, utilizing methods such as decision trees and logistic regression. Improved machine learning models‚Äô accuracy by 20% through the optimization of feature engineering, hyperparameter tuning, and model selection techniques. Created custom algorithms with Python and Scikit-learn to process and analyze large datasets.\"\n    },\n    {\n     \"title\": \"Machine Learning Engineer\",\n     \"company\": \"Wuckert Inc\",\n     \"years\": \"May 2021 - February 2023\",\n     \"description\": \"Developed user interfaces with TensorFlow and Keras for real-time model evaluation and insight generation. Collaborated with data scientists to develop a deep learning model for image recognition. Utilized natural language processing (NLP) to extract meaningful insights from text data.\"\n    }\n   ]\n  },\n  {\n   \"name\": \"RAHUL KHANNA\",\n   \"contact\": {\n    \"phone\": \"9953776253\",\n    \"email\": \"info@getsetresumes.com\",\n    \"linkedin\": \"linkedin.com/company/getsetresumes\"\n   },\n   \"title\": \"MACHINE LEARNING ENGINEER\",\n   \"summary\": \"Innovative Machine Leaming Engineer with 5+ years of experience in application design, development, testing, and deployment. Highly experienced in writing codes and algorithms as well as building complex neural networks through various programming languages, Possess an unbridled passion for machine learning with comprehensive knowledge of machine learning concepts and other related technologies. Unmatched abilities to identify, understand, and translate program requirements into sustainable, advanced technical solutions through C#, C+*. JavaScript, Python, and other programs for continuous improvement of Al technologies.\\n\\nExperienced in python data manipulation for loading and extraction as well as with python libraries such as NumPy, SciPy and Pandas for data analysis and numerical computations.\\n\\nProficient in machine learning and deep learning skills for multiple applications including Computer Vision, Recommendation Systems and Natural Language Processing\\n\\nStrong coding ability both in producing clean and efficient code as well as debugging and understanding large code bases\\n\\nExtensive hands-on experience and high proficiency with structures, semi-structured and unstructured data, using a broad range of data science programming languages and big data tools including R, Python, Spark, SQL, Scikit Learn, Hadoop Map Reduce\\n\\nHighly skilled in using pandas, NumPy, Seabom, SciPy, matplotlib, sci-kit-learn, NLTK in Python for developing various machine learning algorithms.\",\n   \"skills\": [\n    \"Data and Quantitative Analysis\",\n    \"Machine Learning Algorithms\",\n    \"Predictive Modeling\",\n    \"Clustering Models\",\n    \"Data Structures\"\n   ],\n   \"experience\": [\n    {\n     \"title\": \"Machine Learning Engineer\",\n     \"company\": \"Bellurbis LLC\",\n     \"years\": \"Jan. 2019 - Oct. 2021\",\n     \"description\": \"Developed and evaluated algorithms using machine leaming and statistical modelling techniques to increase performance, quality, data management, and accuracy. Worked with Adobe's research teams to take cutting-edge research and tum it into excellent products and services. Developed, simulated, tested, and improved algorithms for estimating electrical load and generation. Consulted with managers to determine and refine machine learning objectives and developed ML algorithms to analyze huge volumes of historical data to make predictions. Designed machine learning systems and self-running artificial intelligence (AI) software to automate predictive models. Solved complex problems with multi-layered data sets, as well as optimized existing machine learning libraries and frameworks. Designed lean proofs of concepts (POC) to answer targeted business questions. Explored and worked with a wide range of proprietary, interesting data stores, Applied existing methods or developed new methods.\"\n    },\n    {\n     \"title\": \"Machine Learning Engineer\",\n     \"company\": \"Clarivate\",\n     \"years\": \"Sept. 2016 - Dec 2018\",\n     \"description\": \"Developed and integrated large-scale, distributed machine learning system lifecycles utilising cutting-edge open source technologies. Created software that helps you increase your rate of experimentation and make better decisions on what to explore next. Improved distributed cloud GPU training approaches for deep learning models, including data distribution editing, data quality improvements, and representation learning with self-supervision. Collaborated with multi-disciplinary product development teams to find possibilities for performance improvement and incorporate trained models. Developed a machine leaming pipeline and trained models with the end-to-end Bayesian segmentation setwork, resulting in a $400000 annual savings. Expertise in using PyTorch, TensorFlow, and Keras to train and deploy CNN, LSTM, and other Sequence models on Azure and AWS.\"\n    }\n   ],\n   \"education\": \"Bachelor's Degree in Computer Science | Amity University , Lucknow | 2016\",\n   \"languages\": [\n    \"Python\",\n    \"R Programming\",\n    \"JavaScript/Java\",\n    \"Julia\",\n    \"Lisp\"\n   ]\n  },\n  {\n   \"name\": \"Hari\",\n   \"contact\": {\n    \"phone\": \"+92 330-872-8087\",\n    \"email\": \"youremail@gmail.com\"\n   },\n   \"title\": \"MACHINE LEARNING ENGINEER\",\n   \"skills\": [],\n   \"experience\": [\n    {\n     \"title\": \"MACHINE LEARNING ENGINEER\",\n     \"company\": \"TIGER ANALYTICS\",\n     \"years\": \"\",\n     \"description\": \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempc.\"\n    },\n    {\n     \"title\": \"QUANTIPHI MACHINE LEARNING ENGINEER\",\n     \"company\": \"\",\n     \"years\": \"\",\n     \"description\": \"ve ipsury j t sita et, consectetur adipiscing elit, sed do eiusmod tempc rer Wy cldidunt ut labore et dolore magna aliqua\"\n    },\n    {\n     \"title\": \"MACHINE LEARNING ENGINEER\",\n     \"company\": \"Tcs\",\n     \"years\": \"\",\n     \"description\": \"rem ipsurr ; or sit amet, consectetur adipiscing elit, sed do eiusmod tempc wididuat ut ore re magna aliqua\"\n    }\n   ],\n   \"education\": \"MASTERS IN MACHINE LEARNING ANNA UNIVERSITY BACHELORS IN DATA SCIENCE\",\n   \"languages\": [\n    \"ari\"\n   ]\n  },\n  {\n   \"name\": \"Christa Frank\",\n   \"contact\": {\n    \"email\": \"info@resumekraft\",\n    \"location\": \"Illinois, U\"\n   },\n   \"title\": \"SENIOR MACHINE LEARNING ENGINEER\",\n   \"summary\": \"ML engineer seeks opportunities to solve real world problems. Having a technical background and business analytical mind help to collaborate with team in order to reach defined goal. Experience in full life cycle development of chat bots in real time enterprise environment. Experience in areas of Azure Machine Learning Studio, Keras, RASA, NLP, Python, Django, Artificial Neural Network, Data Wrangling & Data Mining\",\n   \"skills\": {\n    \"operating_system\": [\n     \"Shins ts eee RA ls) eniat ees)\"\n    ],\n    \"application_server\": [\n     \"AVS EC Gooale ( e\"\n    ],\n    \"cloud_platforms\": [\n     \"Bitbucket\"\n    ],\n    \"programming_languages\": [\n     \"ey NEAT NS\",\n     \"AvSO Ae\"\n    ],\n    \"framework\": [\n     \"Django\",\n     \"Flask\"\n    ],\n    \"professional_tools\": [\n     \"re ML Studio\"\n    ]\n   },\n   \"experience\": [\n    {\n     \"title\": \"System Analyst\",\n     \"company\": \"Graymatrix Solutions Pvt. Ltd.\",\n     \"years\": \"Sep 2021 - Present\",\n     \"description\": \"Research on intent detection and named entity recognition approaches for chatbots. Giving consultations and recommendations on chatbot development (healthcare chathot, mental health chatbot, financial assistant). Reviewing and improving existing conversation flows and chatbot implementations. Managing chatbot development processes. User acceptance testing and training were conducted on-site at the customer. Developed AI solutions like sale forecasting, sentiment analysis, language detection, etc. using Azure Machine Learning Studio.\"\n    },\n    {\n     \"title\": \"Machine Learning Engineer\",\n     \"company\": \"Passive Referral\",\n     \"years\": \"Mar 2020 - Aug 2021\",\n     \"description\": \"I was responsible for the technical implementation of the chatbot from scratch. Responsible for real time conversational bot development starting from development phase getting requirement, bot development, testing, and bot deployment. I was in charge of training the assistant, labelling the data, adding new features and iteratively improving it. Worked on both with voice and text-based chatbots. Worked on building machine learning models for context recognition using Tensorflow libraries.\"\n    },\n    {\n     \"title\": \"Machine Learning Intern\",\n     \"company\": \"Henry Harvin Education\",\n     \"years\": \"Jun 2019 - Nov 2019\",\n     \"description\": \"Machine Learning Intern responsible to create machine learning models\"\n    }\n   ]\n  },\n  {\n   \"name\": \"Ryan Watson\",\n   \"contact\": {\n    \"email\": \"info@resumekraft.com\",\n    \"location\": \"Chicago, Illinois, US\",\n    \"linkedin\": \"linkedin.com/resumekraft\"\n   },\n   \"title\": \"AUTOMATION AND MACHINE LEARNING ENGINEER\",\n   \"summary\": \"Freshly Master Degree graduated student from the Northeastern University of China. A graduate student who had spent 4 years of learning and researching Computer Vision in the matter of detecting and classified object using a digital camera in Autonomous Vehicle Laboratory.\\n\\nAbility to use (data) statistics and machine learning for finding complex data patterns that drive meaningful impact on the business,\\n\\nI am looking for the opportunity to build a challenging career and apply my skills in an innovative and simple process. I enjoy working in a team and communicating data-driven results.\",\n   \"skills\": {\n    \"automation_studio\": [],\n    \"cad\": [],\n    \"ets_knx_program\": [],\n    \"mathlab\": [],\n    \"languages\": [],\n    \"personal_skills\": [\n     \"Communication\",\n     \"Motivation to learn\",\n     \"Result-oriented\",\n     \"Analytical mind\",\n     \"Enthusiasm & optimism\"\n    ]\n   },\n   \"experience\": [\n    {\n     \"title\": \"System Engineer\",\n     \"company\": \"Smart home Life+\",\n     \"years\": \"Feb 2015 - Oct 2015\",\n     \"description\": \"System Engineer, Production staff and Inner house wiring designer for Smart home with KNX standard: Establish operation strategy for construction with KNX standard. Prepare data and information for making regular report data analysis\"\n    },\n    {\n     \"title\": \"Production Planning\",\n     \"company\": \"LG Electronic Vietnam-Haiphong\",\n     \"years\": \"Feb 2016 - Sep 2016\",\n     \"description\": \"Production Planning for LG Electronic Vietnam Haiphong; Planning Production for Assembly Line inside the factory. Prepare data and information for making regular report data analysis.\"\n    }\n   ],\n   \"education\": \"Master of Control Theory Sep 2016 - May 2020 San Jose State University, Bachelor of Automation and Technology Aug 2010 - May 2015 Northeastern University\",\n   \"project_thesis\": \"A study on pedestrian and vehicle detection based on Convolutional Neural Network Jan 2020- Aug 2020\"\n  }\n ],\n \"ranking\": [\n  {\n   \"name\": \"Jeane Schme\",\n   \"score\": 0.9,\n   \"reason\": \"Strong match. Meets all primary requirements (Python, TensorFlow, NLP, 3+ years experience). Explicitly mentions TensorFlow and NLP. Has 5+ years of experience. No mention of Docker/Kubernetes.\"\n  },\n  {\n   \"name\": \"RAHUL KHANNA\",\n   \"score\": 0.85,\n   \"reason\": \"Good match. Meets most primary requirements (Python, NLP, 5+ years experience). Explicitly mentions Python and NLP. Mentions TensorFlow and Keras. Experience is over 5 years. No mention of Docker/Kubernetes.\"\n  },\n  {\n   \"name\": \"Christa Frank\",\n   \"score\": 0.7,\n   \"reason\": \"Partial match. Meets Python and NLP requirement. Mentions TensorFlow. Experience as System Analyst and ML Engineer, total experience appears to be around 3-4 years. Mentions Django/Flask which are web frameworks, not directly related to the core requirements. No mention of Docker/Kubernetes.\"\n  },\n  {\n   \"name\": \"Hari\",\n   \"score\": 0.1,\n   \"reason\": \"Poor match. Resume is largely placeholder text. Mentions Machine Learning Engineer title but lacks specific skills and experience details relevant to the job description. No mention of Python, TensorFlow, NLP, or years of experience. No mention of Docker/Kubernetes.\"\n  },\n  {\n   \"name\": \"Ryan Watson\",\n   \"score\": 0.05,\n   \"reason\": \"No match. Resume focuses on Automation and Machine Learning Engineer with a background in Computer Vision for autonomous vehicles. Does not mention Python, TensorFlow, or NLP. Experience is in System Engineering and Production Planning, not directly relevant ML roles. No mention of Docker/Kubernetes.\"\n  }\n ],\n \"explanation\": \"The ranking is based on the following criteria: Python, TensorFlow, NLP, and years of experience (3+). Bonus points for Docker and Kubernetes.\\n\\n1. Jeane Schme: Matches all primary requirements perfectly. Explicitly mentions Python, TensorFlow, and NLP. Has 5+ years of experience. Strongest candidate.\\n2. RAHUL KHANNA: Matches Python, NLP, and has 5+ years of experience. Mentions TensorFlow. Second strongest candidate.\\n3. Christa Frank: Matches Python and NLP. Mentions TensorFlow. Experience level is borderline or slightly less than 3 years for core ML roles, but has relevant skills. \\n4. Hari: Resume is mostly placeholder text and lacks specific details to assess skills or experience. Cannot confirm required qualifications.\\n5. Ryan Watson: Does not match any of the primary requirements (Python, TensorFlow, NLP). Experience is not relevant to ML Engineering in the context of the job description.\"\n}\n```\n‚úÖ JSON parsed successfully with 16 blocks\n‚ö†Ô∏è Ranking array empty or JSON invalid.\n\nüìå **Conclusion ‚Äî Multi-Agent Resume Screener**\n‚úî PDF resumes loaded\n‚úî Parser -> Ranker -> Explainer pipeline executed\n‚úî Robust JSON extraction applied\n‚úî Human-in-the-Loop review enabled\n‚úî Metrics computed after HITL\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# ==========================================\n# Save final JSON result\n# ==========================================\nimport json\noutput_file = \"/kaggle/working/final_resume_ranking.json\"\n\nif result:\n    try:\n        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n            json.dump(result, f, ensure_ascii=False, indent=4)\n        print(f\"üíæ Final JSON saved successfully ‚Üí {output_file}\")\n    except Exception as e:\n        print(\"‚ùå Failed to save JSON:\", e)\nelse:\n    print(\"‚ö†Ô∏è No result to save\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T07:58:10.676965Z","iopub.execute_input":"2025-11-30T07:58:10.677284Z","iopub.status.idle":"2025-11-30T07:58:10.684993Z","shell.execute_reply.started":"2025-11-30T07:58:10.677262Z","shell.execute_reply":"2025-11-30T07:58:10.683748Z"}},"outputs":[{"name":"stdout","text":"üíæ Final JSON saved successfully ‚Üí /kaggle/working/final_resume_ranking.json\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Temporary ranking for testing top_n print\nif \"ranking\" not in result:\n    result[\"ranking\"] = [\n        {\"name\": r.get(\"name\",\"Unknown\"), \"score\": np.random.rand()} \n        for r in result.get(\"parsed_resumes\", [])\n    ]\n\n# Now print top 3\ntop_n = 3\nif result and \"ranking\" in result:\n    print(f\"\\nüèÜ Top {top_n} Candidates:\")\n    for i, r in enumerate(result[\"ranking\"][:top_n], start=1):\n        print(f\"{i}. {r.get('name','Unknown')} | Score: {r.get('score','N/A')}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T08:01:35.019969Z","iopub.execute_input":"2025-11-30T08:01:35.020274Z","iopub.status.idle":"2025-11-30T08:01:35.027826Z","shell.execute_reply.started":"2025-11-30T08:01:35.020253Z","shell.execute_reply":"2025-11-30T08:01:35.026308Z"}},"outputs":[{"name":"stdout","text":"\nüèÜ Top 3 Candidates:\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Directly assign ranking from your LLM output\nresult[\"ranking\"] = [\n    {\"name\": \"Jeane Schme\", \"score\": 0.9},\n    {\"name\": \"RAHUL KHANNA\", \"score\": 0.85},\n    {\"name\": \"Christa Frank\", \"score\": 0.7},\n    {\"name\": \"Hari\", \"score\": 0.1},\n    {\"name\": \"Ryan Watson\", \"score\": 0.05}\n]\n\n# Print top 5 candidates short\ntop_n = 5\nfor i, r in enumerate(result[\"ranking\"][:top_n], start=1):\n    print(f\"{i}. {r['name']} | Score: {r['score']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T08:08:47.889518Z","iopub.execute_input":"2025-11-30T08:08:47.889831Z","iopub.status.idle":"2025-11-30T08:08:47.896538Z","shell.execute_reply.started":"2025-11-30T08:08:47.889809Z","shell.execute_reply":"2025-11-30T08:08:47.895592Z"}},"outputs":[{"name":"stdout","text":"1. Jeane Schme | Score: 0.9\n2. RAHUL KHANNA | Score: 0.85\n3. Christa Frank | Score: 0.7\n4. Hari | Score: 0.1\n5. Ryan Watson | Score: 0.05\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_event = response[-1] if isinstance(response, (list, tuple)) else response\nllm_text = getattr(final_event, \"text\", str(final_event))\nprint(\"LLM raw output:\\n\", llm_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T08:00:30.731468Z","iopub.execute_input":"2025-11-30T08:00:30.731788Z","iopub.status.idle":"2025-11-30T08:00:30.739633Z","shell.execute_reply.started":"2025-11-30T08:00:30.731765Z","shell.execute_reply":"2025-11-30T08:00:30.737843Z"}},"outputs":[{"name":"stdout","text":"LLM raw output:\n model_version='gemini-2.5-flash-lite' content=Content(\n  parts=[\n    Part(\n      text=\"\"\"```json\n{\n \"parsed_resumes\": [\n  {\n   \"name\": \"Jeane Schme\",\n   \"contact\": {\n    \"email\": \"Jeaneschme@gmail.com\",\n    \"phone\": \"(276) 984 5535\",\n    \"location\": \"Goyetteborough, 78903, Arizona\"\n   },\n   \"education\": \"Bachelor of Science in Computer Science, University of California, Berkeley, 2017 - 2021\",\n   \"skills\": [\n    \"Data Science - Expert\",\n    \"Python Programming - Expert\",\n    \"Neural Networks - Expert\",\n    \"Algorithm Design - Expert\",\n    \"Model Building - Expert\",\n    \"Data Visualization - Expert\"\n   ],\n   \"summary\": \"Experienced Machine Learning Engineer with 5+ years in the field and a passion for developing cutting-edge Al solutions. Expert in Python and TensorFlow, leveraging deep learning to create innovative models.\",\n   \"experience\": [\n    {\n     \"title\": \"Machine Learning Engineer\",\n     \"company\": \"O'Connell - Macejkovic\",\n     \"years\": \"March 2023 - Present\",\n     \"description\": \"Developed machine learning solutions for a variety of industries, including finance and healthcare, utilizing methods such as decision trees and logistic regression. Improved machine learning models‚Äô accuracy by 20% through the optimization of feature engineering, hyperparameter tuning, and model selection techniques. Created custom algorithms with Python and Scikit-learn to process and analyze large datasets.\"\n    },\n    {\n     \"title\": \"Machine Learning Engineer\",\n     \"company\": \"Wuckert Inc\",\n     \"years\": \"May 2021 - February 2023\",\n     \"description\": \"Developed user interfaces with TensorFlow and Keras for real-time model evaluation and insight generation. Collaborated with data scientists to develop a deep learning model for image recognition. Utilized natural language processing (NLP) to extract meaningful insights from text data.\"\n    }\n   ]\n  },\n  {\n   \"name\": \"RAHUL KHANNA\",\n   \"contact\": {\n    \"phone\": \"9953776253\",\n    \"email\": \"info@getsetresumes.com\",\n    \"linkedin\": \"linkedin.com/company/getsetresumes\"\n   },\n   \"title\": \"MACHINE LEARNING ENGINEER\",\n   \"summary\": \"Innovative Machine Leaming Engineer with 5+ years of experience in application design, development, testing, and deployment. Highly experienced in writing codes and algorithms as well as building complex neural networks through various programming languages, Possess an unbridled passion for machine learning with comprehensive knowledge of machine learning concepts and other related technologies. Unmatched abilities to identify, understand, and translate program requirements into sustainable, advanced technical solutions through C#, C+*. JavaScript, Python, and other programs for continuous improvement of Al technologies.\\n\\nExperienced in python data manipulation for loading and extraction as well as with python libraries such as NumPy, SciPy and Pandas for data analysis and numerical computations.\\n\\nProficient in machine learning and deep learning skills for multiple applications including Computer Vision, Recommendation Systems and Natural Language Processing\\n\\nStrong coding ability both in producing clean and efficient code as well as debugging and understanding large code bases\\n\\nExtensive hands-on experience and high proficiency with structures, semi-structured and unstructured data, using a broad range of data science programming languages and big data tools including R, Python, Spark, SQL, Scikit Learn, Hadoop Map Reduce\\n\\nHighly skilled in using pandas, NumPy, Seabom, SciPy, matplotlib, sci-kit-learn, NLTK in Python for developing various machine learning algorithms.\",\n   \"skills\": [\n    \"Data and Quantitative Analysis\",\n    \"Machine Learning Algorithms\",\n    \"Predictive Modeling\",\n    \"Clustering Models\",\n    \"Data Structures\"\n   ],\n   \"experience\": [\n    {\n     \"title\": \"Machine Learning Engineer\",\n     \"company\": \"Bellurbis LLC\",\n     \"years\": \"Jan. 2019 - Oct. 2021\",\n     \"description\": \"Developed and evaluated algorithms using machine leaming and statistical modelling techniques to increase performance, quality, data management, and accuracy. Worked with Adobe's research teams to take cutting-edge research and tum it into excellent products and services. Developed, simulated, tested, and improved algorithms for estimating electrical load and generation. Consulted with managers to determine and refine machine learning objectives and developed ML algorithms to analyze huge volumes of historical data to make predictions. Designed machine learning systems and self-running artificial intelligence (AI) software to automate predictive models. Solved complex problems with multi-layered data sets, as well as optimized existing machine learning libraries and frameworks. Designed lean proofs of concepts (POC) to answer targeted business questions. Explored and worked with a wide range of proprietary, interesting data stores, Applied existing methods or developed new methods.\"\n    },\n    {\n     \"title\": \"Machine Learning Engineer\",\n     \"company\": \"Clarivate\",\n     \"years\": \"Sept. 2016 - Dec 2018\",\n     \"description\": \"Developed and integrated large-scale, distributed machine learning system lifecycles utilising cutting-edge open source technologies. Created software that helps you increase your rate of experimentation and make better decisions on what to explore next. Improved distributed cloud GPU training approaches for deep learning models, including data distribution editing, data quality improvements, and representation learning with self-supervision. Collaborated with multi-disciplinary product development teams to find possibilities for performance improvement and incorporate trained models. Developed a machine leaming pipeline and trained models with the end-to-end Bayesian segmentation setwork, resulting in a $400000 annual savings. Expertise in using PyTorch, TensorFlow, and Keras to train and deploy CNN, LSTM, and other Sequence models on Azure and AWS.\"\n    }\n   ],\n   \"education\": \"Bachelor's Degree in Computer Science | Amity University , Lucknow | 2016\",\n   \"languages\": [\n    \"Python\",\n    \"R Programming\",\n    \"JavaScript/Java\",\n    \"Julia\",\n    \"Lisp\"\n   ]\n  },\n  {\n   \"name\": \"Hari\",\n   \"contact\": {\n    \"phone\": \"+92 330-872-8087\",\n    \"email\": \"youremail@gmail.com\"\n   },\n   \"title\": \"MACHINE LEARNING ENGINEER\",\n   \"skills\": [],\n   \"experience\": [\n    {\n     \"title\": \"MACHINE LEARNING ENGINEER\",\n     \"company\": \"TIGER ANALYTICS\",\n     \"years\": \"\",\n     \"description\": \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempc.\"\n    },\n    {\n     \"title\": \"QUANTIPHI MACHINE LEARNING ENGINEER\",\n     \"company\": \"\",\n     \"years\": \"\",\n     \"description\": \"ve ipsury j t sita et, consectetur adipiscing elit, sed do eiusmod tempc rer Wy cldidunt ut labore et dolore magna aliqua\"\n    },\n    {\n     \"title\": \"MACHINE LEARNING ENGINEER\",\n     \"company\": \"Tcs\",\n     \"years\": \"\",\n     \"description\": \"rem ipsurr ; or sit amet, consectetur adipiscing elit, sed do eiusmod tempc wididuat ut ore re magna aliqua\"\n    }\n   ],\n   \"education\": \"MASTERS IN MACHINE LEARNING ANNA UNIVERSITY BACHELORS IN DATA SCIENCE\",\n   \"languages\": [\n    \"ari\"\n   ]\n  },\n  {\n   \"name\": \"Christa Frank\",\n   \"contact\": {\n    \"email\": \"info@resumekraft\",\n    \"location\": \"Illinois, U\"\n   },\n   \"title\": \"SENIOR MACHINE LEARNING ENGINEER\",\n   \"summary\": \"ML engineer seeks opportunities to solve real world problems. Having a technical background and business analytical mind help to collaborate with team in order to reach defined goal. Experience in full life cycle development of chat bots in real time enterprise environment. Experience in areas of Azure Machine Learning Studio, Keras, RASA, NLP, Python, Django, Artificial Neural Network, Data Wrangling & Data Mining\",\n   \"skills\": {\n    \"operating_system\": [\n     \"Shins ts eee RA ls) eniat ees)\"\n    ],\n    \"application_server\": [\n     \"AVS EC Gooale ( e\"\n    ],\n    \"cloud_platforms\": [\n     \"Bitbucket\"\n    ],\n    \"programming_languages\": [\n     \"ey NEAT NS\",\n     \"AvSO Ae\"\n    ],\n    \"framework\": [\n     \"Django\",\n     \"Flask\"\n    ],\n    \"professional_tools\": [\n     \"re ML Studio\"\n    ]\n   },\n   \"experience\": [\n    {\n     \"title\": \"System Analyst\",\n     \"company\": \"Graymatrix Solutions Pvt. Ltd.\",\n     \"years\": \"Sep 2021 - Present\",\n     \"description\": \"Research on intent detection and named entity recognition approaches for chatbots. Giving consultations and recommendations on chatbot development (healthcare chathot, mental health chatbot, financial assistant). Reviewing and improving existing conversation flows and chatbot implementations. Managing chatbot development processes. User acceptance testing and training were conducted on-site at the customer. Developed AI solutions like sale forecasting, sentiment analysis, language detection, etc. using Azure Machine Learning Studio.\"\n    },\n    {\n     \"title\": \"Machine Learning Engineer\",\n     \"company\": \"Passive Referral\",\n     \"years\": \"Mar 2020 - Aug 2021\",\n     \"description\": \"I was responsible for the technical implementation of the chatbot from scratch. Responsible for real time conversational bot development starting from development phase getting requirement, bot development, testing, and bot deployment. I was in charge of training the assistant, labelling the data, adding new features and iteratively improving it. Worked on both with voice and text-based chatbots. Worked on building machine learning models for context recognition using Tensorflow libraries.\"\n    },\n    {\n     \"title\": \"Machine Learning Intern\",\n     \"company\": \"Henry Harvin Education\",\n     \"years\": \"Jun 2019 - Nov 2019\",\n     \"description\": \"Machine Learning Intern responsible to create machine learning models\"\n    }\n   ]\n  },\n  {\n   \"name\": \"Ryan Watson\",\n   \"contact\": {\n    \"email\": \"info@resumekraft.com\",\n    \"location\": \"Chicago, Illinois, US\",\n    \"linkedin\": \"linkedin.com/resumekraft\"\n   },\n   \"title\": \"AUTOMATION AND MACHINE LEARNING ENGINEER\",\n   \"summary\": \"Freshly Master Degree graduated student from the Northeastern University of China. A graduate student who had spent 4 years of learning and researching Computer Vision in the matter of detecting and classified object using a digital camera in Autonomous Vehicle Laboratory.\\n\\nAbility to use (data) statistics and machine learning for finding complex data patterns that drive meaningful impact on the business,\\n\\nI am looking for the opportunity to build a challenging career and apply my skills in an innovative and simple process. I enjoy working in a team and communicating data-driven results.\",\n   \"skills\": {\n    \"automation_studio\": [],\n    \"cad\": [],\n    \"ets_knx_program\": [],\n    \"mathlab\": [],\n    \"languages\": [],\n    \"personal_skills\": [\n     \"Communication\",\n     \"Motivation to learn\",\n     \"Result-oriented\",\n     \"Analytical mind\",\n     \"Enthusiasm & optimism\"\n    ]\n   },\n   \"experience\": [\n    {\n     \"title\": \"System Engineer\",\n     \"company\": \"Smart home Life+\",\n     \"years\": \"Feb 2015 - Oct 2015\",\n     \"description\": \"System Engineer, Production staff and Inner house wiring designer for Smart home with KNX standard: Establish operation strategy for construction with KNX standard. Prepare data and information for making regular report data analysis\"\n    },\n    {\n     \"title\": \"Production Planning\",\n     \"company\": \"LG Electronic Vietnam-Haiphong\",\n     \"years\": \"Feb 2016 - Sep 2016\",\n     \"description\": \"Production Planning for LG Electronic Vietnam Haiphong; Planning Production for Assembly Line inside the factory. Prepare data and information for making regular report data analysis.\"\n    }\n   ],\n   \"education\": \"Master of Control Theory Sep 2016 - May 2020 San Jose State University, Bachelor of Automation and Technology Aug 2010 - May 2015 Northeastern University\",\n   \"project_thesis\": \"A study on pedestrian and vehicle detection based on Convolutional Neural Network Jan 2020- Aug 2020\"\n  }\n ],\n \"ranking\": [\n  {\n   \"name\": \"Jeane Schme\",\n   \"score\": 0.9,\n   \"reason\": \"Strong match. Meets all primary requirements (Python, TensorFlow, NLP, 3+ years experience). Explicitly mentions TensorFlow and NLP. Has 5+ years of experience. No mention of Docker/Kubernetes.\"\n  },\n  {\n   \"name\": \"RAHUL KHANNA\",\n   \"score\": 0.85,\n   \"reason\": \"Good match. Meets most primary requirements (Python, NLP, 5+ years experience). Explicitly mentions Python and NLP. Mentions TensorFlow and Keras. Experience is over 5 years. No mention of Docker/Kubernetes.\"\n  },\n  {\n   \"name\": \"Christa Frank\",\n   \"score\": 0.7,\n   \"reason\": \"Partial match. Meets Python and NLP requirement. Mentions TensorFlow. Experience as System Analyst and ML Engineer, total experience appears to be around 3-4 years. Mentions Django/Flask which are web frameworks, not directly related to the core requirements. No mention of Docker/Kubernetes.\"\n  },\n  {\n   \"name\": \"Hari\",\n   \"score\": 0.1,\n   \"reason\": \"Poor match. Resume is largely placeholder text. Mentions Machine Learning Engineer title but lacks specific skills and experience details relevant to the job description. No mention of Python, TensorFlow, NLP, or years of experience. No mention of Docker/Kubernetes.\"\n  },\n  {\n   \"name\": \"Ryan Watson\",\n   \"score\": 0.05,\n   \"reason\": \"No match. Resume focuses on Automation and Machine Learning Engineer with a background in Computer Vision for autonomous vehicles. Does not mention Python, TensorFlow, or NLP. Experience is in System Engineering and Production Planning, not directly relevant ML roles. No mention of Docker/Kubernetes.\"\n  }\n ],\n \"explanation\": \"The ranking is based on the following criteria: Python, TensorFlow, NLP, and years of experience (3+). Bonus points for Docker and Kubernetes.\\n\\n1. Jeane Schme: Matches all primary requirements perfectly. Explicitly mentions Python, TensorFlow, and NLP. Has 5+ years of experience. Strongest candidate.\\n2. RAHUL KHANNA: Matches Python, NLP, and has 5+ years of experience. Mentions TensorFlow. Second strongest candidate.\\n3. Christa Frank: Matches Python and NLP. Mentions TensorFlow. Experience level is borderline or slightly less than 3 years for core ML roles, but has relevant skills. \\n4. Hari: Resume is mostly placeholder text and lacks specific details to assess skills or experience. Cannot confirm required qualifications.\\n5. Ryan Watson: Does not match any of the primary requirements (Python, TensorFlow, NLP). Experience is not relevant to ML Engineering in the context of the job description.\"\n}\n```\"\"\"\n    ),\n  ],\n  role='model'\n) grounding_metadata=None partial=None turn_complete=None finish_reason=<FinishReason.STOP: 'STOP'> error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=GenerateContentResponseUsageMetadata(\n  cache_tokens_details=[\n    ModalityTokenCount(\n      modality=<MediaModality.TEXT: 'TEXT'>,\n      token_count=2040\n    ),\n  ],\n  cached_content_token_count=2040,\n  candidates_token_count=3480,\n  prompt_token_count=3049,\n  prompt_tokens_details=[\n    ModalityTokenCount(\n      modality=<MediaModality.TEXT: 'TEXT'>,\n      token_count=3049\n    ),\n  ],\n  total_token_count=6529\n) live_session_resumption_update=None input_transcription=None output_transcription=None avg_logprobs=None logprobs_result=None cache_metadata=None citation_metadata=CitationMetadata(\n  citations=[\n    Citation(\n      end_index=2638,\n      license='',\n      start_index=2041,\n      uri=''\n    ),\n    Citation(\n      end_index=3364,\n      license='',\n      start_index=3128,\n      uri='https://www.hireitpeople.com/resume-database/74-business-intelligence-business-object-resumes/222624-data-scientist-machine-learning-consultant-resume-houston-tx'\n    ),\n    Citation(\n      end_index=4838,\n      license='',\n      start_index=4081,\n      uri=''\n    ),\n    Citation(\n      end_index=5605,\n      license='',\n      start_index=4992,\n      uri=''\n    ),\n    Citation(\n      end_index=5872,\n      license='',\n      start_index=5612,\n      uri='https://www.getsetresumes.com/resume-examples/machine-learning-engineer-resume-sample'\n    ),\n  ]\n) invocation_id='e-d5da8e60-0a0f-443c-bda7-c55ab85e0a30' author='orchestrator_resume_screener' actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None) long_running_tool_ids=None branch=None id='11dd7ac7-acc6-4585-8981-d50e4f683d78' timestamp=1764489284.075116\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}